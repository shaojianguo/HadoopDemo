package com.atguigu.hdfs;

import java.io.IOException;
import java.net.URI;
import java.net.URISyntaxException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.junit.Test;

public class HdfsClient {
	public static void main(String[] args) throws Exception{
		
		Configuration conf = new Configuration();
		
		
		
		FileSystem fs = FileSystem.get(new URI("hdfs://hadoop101:9000"), conf, "atguigu");
		
		fs.mkdirs(new Path("/0705/xueba/daniuban"));
		
		fs.close();
		
		
	}
	
	@Test
	public void tesCopyFromLocalFile() throws IOException, InterruptedException, URISyntaxException {
		
		//1 获取文件系统
		Configuration conf = new Configuration();
		FileSystem fs = FileSystem.get(new URI("hdfs://hadoop101:9000"), conf, "atguigu");
		
		//2 上传文件
		fs.copyFromLocalFile(new Path("e:/aaa.pdf"), new Path("/aaa.pdf"));

		//3 关闭资源
		fs.close();
	}
	
	@Test
	public void testCopyToLocalFile() throws IOException, InterruptedException, URISyntaxException {
		
		//1 获取文件系统
		Configuration conf= new Configuration() ;
		FileSystem fs = FileSystem.get(new URI("hdfs://hadoop101:9000"), conf , "atguigu");
		
		//2 执行下载操作
		fs.copyToLocalFile(false, new Path("/bbb.pdf"), new Path("e:/ccc.pdf"), true);
		
		//3 关闭资源
		fs.close();
	}
	
	@Test
	public void testDelete() throws IOException, InterruptedException, URISyntaxException {
		
		//1 获取文件系统
		Configuration conf= new Configuration() ;
		FileSystem fs = FileSystem.get(new URI("hdfs://hadoop101:9000"), conf, "atguigu");
		
		//2 执行删除
		fs.delete(new Path("/aaa.pdf"), true);
		
		//3 关闭资源
		fs.close();
	}
	
	
}
