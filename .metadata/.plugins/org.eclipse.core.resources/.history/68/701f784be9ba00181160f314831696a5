package com.atguigu.hdfs;

import java.net.URI;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.junit.Test;

public class HdfsClient {
	public static void main(String[] args) throws Exception{
		
		Configuration conf = new Configuration();
		
		
		
		FileSystem fs = FileSystem.get(new URI("hdfs://hadoop101:9000"), conf, "atguigu");
		
		fs.mkdirs(new Path("/0705/xueba/daniuban"));
		
		fs.close();
		
		
	}
	
	
	//文件上传
	@Test
	public void testCopyFromLocalFile() throws Exception{
	
		//1 获取文件
		Configuration conf = new Configuration();
		
		FileSystem fs = FileSystem.get(new URI("hdfs://hadoop101:9000"), conf, "atguigu");
		
		//2 上传文件
		fs.copyFromLocalFile(new Path("e:/aaa.pdf"), new Path("/aaa.pdf"));
		
		//3 关闭资源
		
		fs.close();
		
		System.out.println("over");
	}
	
}
